{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f655c7b",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Makueni is experiencing an epidemiological transition in its diseases burden from communicable to non-communicable conditions resulting in the double burden of disease. In Makueni County, according to DHIS 2018, cases of hypertension recorded were 78,572 compared to 2017 cases recorded at 50,522 while diabetes cases in 2018 recorded were 21,426 compared to 12,609 in 2017.\n",
    "Management of related complications costs are alarming when considering any emergency aspects, the management of complications as well as rehabilitation costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd126d",
   "metadata": {},
   "source": [
    "# Importing Libraries:\n",
    "-For completing any task we require tools, and we have plenty of tools in python. Letâ€™s start with importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b36165d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (from imblearn) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c3c400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\ken bwire\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13e29ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1527b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Ken Bwire/Desktop/DM $ HTN Data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/Ken Bwire/Desktop/DM $ HTN Data.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1248\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1253\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1254\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Ken Bwire/Desktop/DM $ HTN Data.xlsx'"
     ]
    }
   ],
   "source": [
    "data=pd.read_excel(\"C:/Users/Ken Bwire/Desktop/DM $ HTN Data.xlsx\")\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a17799",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc06142",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Displaying top 10 rows\n",
    "data.info()\n",
    "## Showing information about datase\n",
    "data.describe()\n",
    "## Showing data's statistical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d86bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique values\\n',data['sex'].unique())\n",
    "print('Value Counts\\n',data['sex'].value_counts())\n",
    "# Above codes will help to give us information about it's unique values and count of each value.\n",
    "\n",
    "sns.countplot(data=data,x='sex')\n",
    "# Helps to plot a count plot which will help us to see count of values in each unique category.\n",
    "sns.countplot(data=data,x='sex',hue='Diagnosis')\n",
    "# This plot will help to analyze how sex will affect chances of Diagnosis/type of hypertension and Diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6732ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Value\\n',data['Location'].unique())\n",
    "print('Value Counts\\n',data['Location'].value_counts())\n",
    "# Above code will return unique value for Location/cluster/ward/village name attribute and its value counts\n",
    "sns.countplot(data=data,x='Location')\n",
    "#Will plot a counter plot of variable Location/Cluster/Ward/Village. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Value\\n',data['Education'].unique())\n",
    "print('Value Counts\\n',data['Education'].value_counts())\n",
    "# Above code will return unique value for Education level attribute and its value counts\n",
    "sns.countplot(data=data,x='Education')\n",
    "# Will plot a counter plot of variable Location/Cluster/Ward/Village. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Value\\n',data['Frequency of clinic visit'].unique())\n",
    "print('Value Counts\\n',data['Frequency of clinic visit'].value_counts())\n",
    "# Above code will return unique values of attributes and its count\n",
    "sns.countplot(data=data,x='Frequency of clinic visit')\n",
    "# Above code will create a count plot\n",
    "sns.countplot(data=data,x='Frequency of clinic visit',hue='Diagnosis')\n",
    "# Above code will create a count plot with respect to Diagnosis/type of hypertension and Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3346b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Values\\n',data['Weight'].unique())\n",
    "print(\"Value Counts\\n\",data['Weight'].value_counts())\n",
    "# Above code will return unique values of variable and its count\n",
    "sns.countplot(data=data,x='Weight')\n",
    "# This will create a counter plot\n",
    "sns.countplot(data=data,x='Weight',hue='Diagnosis')\n",
    "# Weight with respect to Diagnosis/type of hypertension and Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BMI'].nunique()\n",
    "# Number of unique values\n",
    "sns.displot(data['BMI'])\n",
    "# Distribution of avg_glucose_level\n",
    "sns.boxplot(data=data,x='Diagnosis',y='BMI')\n",
    "# BMI and Diagnosis/type of hypertension and Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f7dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BMI'].isna().sum()\n",
    "# Returns number null values\n",
    "data['BMI'].fillna(data['BMI'].mean(),inplace=True)\n",
    "# Filling null values with average value\n",
    "data['BMI'].nunique()\n",
    "# Returns number of unique values in that attribute\n",
    "sns.displot(data['BMI'])\n",
    "# Distribution of bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Values\\n',data['BP Systolic'].unique())\n",
    "print('Value Counts\\n',data['BP Systolic'].value_counts())\n",
    "# Returns unique values and its count\n",
    "sns.countplot(data=data,x='BP Systolic')\n",
    "# Count plot of smoking status\n",
    "sns.countplot(data=data,x='BP Systolic',hue='Diagnosis')\n",
    "# BP Systolic with respect to Diagnosis/type of hypertension and Diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Values\\n',data['BP Diastolic'].unique())\n",
    "print('Value Counts\\n',data['BP Diastolic'].value_counts())\n",
    "# Returns unique values and its count\n",
    "sns.countplot(data=data,x='BP Diastolic')\n",
    "# Count plot of BP Diastolic\n",
    "sns.countplot(data=data,x='BP Diastolic',hue='Diagnosis')\n",
    "# BP Diastolic with respect to Diagnosis/type of hypertension and Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Value\\n',data['Diagnosis'].unique())\n",
    "print('Value Counts\\n',data['Diagnosis'].value_counts())\n",
    "# Returns Unique Value and its count\n",
    "sns.countplot(data=data,x='Diagnosis')\n",
    "# Count Plot of Diagnosis/type of hypertension and Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=data.select_dtypes(include=['object']).columns\n",
    "print(cols)\n",
    "# This code will fetech columns whose data type is object.\n",
    "le=LabelEncoder()\n",
    "# Initializing our Label Encoder object\n",
    "data[cols]=data[cols].apply(le.fit_transform)\n",
    "# Transfering categorical data into numeric\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9327eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "# seaborn has an easy method to showcase heatmap\n",
    "p = sns.heatmap(data.corr(), annot=True,cmap ='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = data.hist(figsize = (20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a831eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SelectKBest(score_func=f_classif,k=5)\n",
    "fits = classifier.fit(data.drop('Diagnosis',axis=1),data['Diagnosis'])\n",
    "x=pd.DataFrame(fits.scores_)\n",
    "columns = pd.DataFrame(data.drop('Diagnosis',axis=1).columns)\n",
    "fscores = pd.concat([columns,x],axis=1)\n",
    "fscores.columns = ['Attribute','Score']\n",
    "fscores.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f100e",
   "metadata": {},
   "source": [
    "# Scaling the Data\n",
    "Before scaling down the data letâ€™s have a look into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5801ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X =  pd.DataFrame(sc_X.fit_transform(data.drop([\"Diagnosis\"],axis = 1),), columns=['sex', \n",
    "'Age', 'Location', 'Frequency of clinic visit', 'Education','Weight','BMI', 'BP Diastolic', 'BP Systolic'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085226bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Diagnosis']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83db9be",
   "metadata": {},
   "source": [
    "# Modelling Building \n",
    "Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da06087",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Diagnosis', axis=1)\n",
    "y = data['Diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e355374",
   "metadata": {},
   "source": [
    "#Split the data into training and testing data using the train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33,random_state=7)\n",
    "#Shape of the data\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape\n",
    "# Shape of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b9782",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Building the model using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "#Fit the model\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f36fb",
   "metadata": {},
   "source": [
    "#Building the model letâ€™s check the accuracy of the model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here we can see that on the training dataset our model is overfitted.\")\n",
    "rfc_train = rfc.predict(X_train)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy_Score =\", format(metrics.accuracy_score(y_train, rfc_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3afe8",
   "metadata": {},
   "source": [
    "# Getting the accuracy score for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ed623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predictions = rfc.predict(X_test)\n",
    "print(\"Accuracy_Score =\", format(metrics.accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e23c32",
   "metadata": {},
   "source": [
    "# Classification report and confusion matrix of random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73559c",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "Building the model using DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c92dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477a453",
   "metadata": {},
   "source": [
    "# Getting the accuracy score for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921bbd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predictions = dtree.predict(X_test)\n",
    "print(\"Accuracy Score =\", format(metrics.accuracy_score(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3178260",
   "metadata": {},
   "source": [
    "# Classification report and confusion matrix of the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292be534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(gamma=0)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef8c8c",
   "metadata": {},
   "source": [
    "# XgBoost classifier\n",
    "Building model using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db43b0",
   "metadata": {},
   "source": [
    "# Getting the accuracy score for the XgBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f79301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "print(\"Accuracy Score =\", format(metrics.accuracy_score(y_test, xgb_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6879e414",
   "metadata": {},
   "source": [
    "# Classification report and confusion matrix of the XgBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, xgb_pred))\n",
    "print(classification_report(y_test,xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4384aaf",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "Building the model using Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction from support vector machine model on the testing data\n",
    "\n",
    "svc_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score for SVM\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy Score =\", format(metrics.accuracy_score(y_test, svc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report and confusion matrix of the SVM classifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, svc_pred))\n",
    "print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd36976",
   "metadata": {},
   "source": [
    "# The Conclusion from Model Building\n",
    "Therefore Random forest is the best model for this prediction since it has an accuracy_score of 0.73."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97d6ae",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "Knowing about the feature importance is quite necessary as it shows that how much weightage each feature provides in the model building phase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e1f10f",
   "metadata": {},
   "source": [
    "#Getting feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000cc31a",
   "metadata": {},
   "source": [
    "# Visualization of the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9de1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f34524",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(rfc.feature_importances_, index=X.columns).plot(kind='barh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15885525",
   "metadata": {},
   "source": [
    "# Saving Model Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a43400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Firstly we will be using the dump() function to save the model using pickle\n",
    "saved_model = pickle.dumps(rfc)\n",
    "\n",
    "# Then we will be loading that saved model\n",
    "rfc_from_pickle = pickle.loads(saved_model)\n",
    "\n",
    "# lastly, after loading that model we will use this to make predictions\n",
    "rfc_from_pickle.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c769023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command will basically import all the modules from pycaret that are necessary for classification tasks\n",
    "from pycaret.classification import *\n",
    "# Setting up the classifier\n",
    "# Pass the complete dataset as data and the featured to be predicted as target\n",
    "clf=setup(data=data,target='Diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5dac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ff66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c574e2",
   "metadata": {},
   "source": [
    "# The prediction is given by the following ;\n",
    "0. No Hypertension and Diabetes.\n",
    "1. Hypertension value.\n",
    "2. Hypertension and Diabetes\n",
    "3. Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31403168",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.predict([[0,51,274,0,8,67.0,27.53,91,145]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15798143",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.predict([[0,71,62,0,4,51.0,23.92,66,126]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5eace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.predict([[0,34,125,0,7,34.98,20.21,98,231]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.predict([[1,25,45,0,7,21.34,37.90,72,92]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a predict function to be passed into gradio UI\n",
    "def predict(sex,Age,Location,Frequency of clinic visit,Education,Weight,BMI,BP Diastolic,BP Systolic):\n",
    "  \n",
    "    data = pd.DataFrame.from_dict({'sex': [sex], 'Age': [Age], 'Location': [Location], 'Frequency_of_clinic_visit':[Frequency of clinic visit],'Education':[Education],\n",
    "                                 'Weight': [weight], 'BMI': [BMI], 'BP Diastolic': [BP Diastolic],'BP_Systolic':[BP Systolic]})\n",
    "    model_index = list(compare_model_results['Model']).index(model)\n",
    "    model = best[model_index]\n",
    "    pred = predict_model(model, data, raw_score=True)\n",
    "    return {'Yes': pred['Score_Yes'][0].astype('float64'), \n",
    "            'No': pred['Score_No'][0].astype('float64' )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f97248",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gr.inputs.Dropdown(list(compare_model_results['Model']),label=\"Model\")\n",
    "sex = gr.inputs.Dropdown(choices=[\"Male\", \"Female\"],label = 'sex')\n",
    "Age = gr.inputs.Slider(minimum=1, maximum=100, default=data['Age'].mean(), label = 'Age')\n",
    "Location = gr.inputs.Dropdown(choices=[\"Makueni\", \"Kaiti\",\"Mbooni\", \"Kilome\",\"Kibwezi West\",\"Kibwezi East\"], label ='Location')\n",
    "Education=gr.inputs.Dropdown(choices=[\"Yes\",\"No\"],label=\"Education\")\n",
    "Frequency_of_clinic_visit = gr.inputs.Slider(minimum=1, maximum=100, default=data['Frequency_of_clinic_visit'].mean(), label = 'Frequency_of_clinic_visit')\n",
    "Weight= gr.inputs.Slider(minimum=-10, maximum=100, default=data['Weight'].mean(), label = 'Weight')\n",
    "BMI= gr.inputs.Slider(minimum=-10, maximum=100, default=data['BMI'].mean(), label = 'BMI')\n",
    "BP_Diastolic =gr.inputs.Slider(minimum=-55, maximum=300, default=data['BP Diastolic'].mean(), label = 'BP Diastolic')\n",
    "BP_Systolic =gr.inputs.Slider(minimum=-55, maximum=300, default=data['BP Systolic'].mean(), label = 'BP Systolic')\n",
    "gr.Interface(predict,[model, sex,Age,Location,Frequency of clinic visit,Education,Weight,BMI,BP Diastolic,BP Systolic], \"label\",live=True).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd0bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
